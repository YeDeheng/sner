How	O
to	O
write	O
an	O
efficient	O
hit	O
counter	O
for	O
websites	O

I	O
want	O
to	O
write	O
a	O
hit	O
counter	O
script	O
to	O
keep	O
track	O
of	O
hits	O
on	O
images	O
on	O
a	O
website	O
and	O
the	O
originating	O
IPs	O
.	O

Impressions	O
are	O
upwards	O
of	O
hundreds	O
of	O
thousands	O
per	O
day	O
,	O
so	O
the	O
counters	O
will	O
be	O
incremented	O
many	O
times	O
a	O
second	O
.	O

I'm	O
looking	O
for	O
a	O
simple	O
,	O
self-hosted	O
method	O
(	O
php	B-PL
,	O
python	B-PL
scripts	O
,	O
etc	O
.	O
)	O
.	O

I	O
was	O
thinking	O
of	O
using	O
MySQL	O
to	O
keep	O
track	O
of	O
this	O
,	O
but	O
I'm	O
guessing	O
there	O
'	O
s	O
a	O
more	O
efficient	O
way	O
.	O

What	O
are	O
good	O
methods	O
of	O
keeping	O
counters	O
?	O

Well	O
if	O
you	O
happen	O
to	O
go	O
the	O
PHP	B-PL
route	O
you	O
could	O
use	O
an	O
SQLite	B-Fram
database	O
,	O
however	O
MySQL	O
is	O
a	O
perfectly	O
reasonable	O
way	O
to	O
store	O
that	O
info	O
and	O
usually	O
(	O
at	O
least	O
from	O
the	O
ones	O
I've	O
seen	O
)	O
is	O
how	O
it	O
is	O
done	O
.	O

If	O
you	O
didn't	O
want	O
to	O
store	O
IP	O
address	O
and	O
any	O
other	O
info	O
a	O
simple	O
number	O
in	O
atext	O
file	O
could	O
work	O
.	O

A	O
fascinating	O
subject	O
.	O

Incrementing	O
a	O
counter	O
,	O
simple	O
as	O
it	O
may	O
be	O
,	O
just	O
has	O
to	O
be	O
a	O
transaction	O
...	O
meaning	O
,	O
it	O
can	O
lock	O
out	O
the	O
whole	O
DB	O
for	O
longer	O
than	O
makes	O
sense	O
!	O

-	O
)	O
It	O
can	O
easily	O
be	O
the	O
bottleneck	O
for	O
the	O
whole	O
system	O
.	O

If	O
you	O
need	O
rigorously	O
exact	O
counts	O
but	O
don't	O
need	O
them	O
to	O
be	O
instantly	O
up-to-date	O
,	O
my	O
favorite	O
approach	O
is	O
to	O
append	O
the	O
countable	O
information	O
to	O
a	O
log	O
(	O
switching	O
logs	O
as	O
often	O
as	O
needed	O
for	O
data	O
freshness	O
purposes	O
)	O
.	O

Once	O
a	O
log	O
is	O
closed	O
(	O
with	O
thousands	O
of	O
countable	O
events	O
in	O
it	O
)	O
,	O
a	O
script	O
can	O
read	O
it	O
and	O
update	O
all	O
that	O
'	O
s	O
needed	O
in	O
a	O
single	O
transaction	O
--	O
maybe	O
not	O
intuitive	O
,	O
but	O
much	O
faster	O
than	O
thousands	O
of	O
single	O
locks	O
.	O

Then	O
there	O
'	O
s	O
extremely-fast	O
counters	O
that	O
are	O
only	O
statistically	O
accurate	O
--	O
but	O
since	O
you	O
don't	O
say	O
that	O
such	O
imprecision	O
is	O
acceptable	O
,	O
I'm	O
not	O
going	O
to	O
explain	O
them	O
in	O
more	O
depth	O
.	O

There	O
are	O
two	O
really	O
easy	O
ways	O
:	O

Parse	O
it	O
out	O
of	O
your	O
web	O
logs	O
in	O
batch	O
.	O

Run	O
the	O
hits	O
through	O
beanstalkd	O
or	O
gearmand	O
and	O
have	O
a	O
worker	O
do	O
the	O
hard	O
stuff	O
in	O
a	O
controlled	O
way	O
.	O

Option	O
1	O
works	O
with	O
off-the-shelf	O
tools	O
.	O

Option	O
2	O
requires	O
just	O
a	O
bit	O
of	O
programming	O
,	O
but	O
gives	O
you	O
something	O
closer	O
to	O
realtime	O
updates	O
without	O
causing	O
you	O
to	O
fall	O
over	O
when	O
the	O
traffic	O
spikes	O
(	O
such	O
as	O
you'll	O
find	O
in	O
your	O
direct	O
mysql	O
case	O
)	O
.	O

Not	O
sure	O
if	O
it	O
'	O
s	O
up	O
your	O
alley	O
,	O
but	O
AppEngine	B-API
is	O
a	O
pretty	O
nice	O
platform	O
to	O
build	O
on	O
.	O

Some	O
sample	O
code	O
you	O
can	O
use	O
to	O
build	O
a	O
counter	O
using	O
their	O
DataStore	B-API
and	O
transactions	O
is	O
described	O
here	O
:	O
http://code.google.com/appengine/docs/python/datastore/transactions.html	O
.	O

If	O
accuracy	O
is	O
important	O
,	O
you	O
can	O
do	O
it	O
slightly	O
slower	O
with	O
MySql	B-API
...	O
create	O
a	O
HEAP	O
/	O
Memory	O
table	O
to	O
store	O
your	O
counter	O
values	O
.	O

These	O
a	O
in-memory	O
tables	O
that	O
are	O
blazingly	O
fast	O
.	O

You	O
can	O
write	O
the	O
data	O
into	O
a	O
normal	O
table	O
at	O
intervals	O
.	O

Based	O
on	O
the	O
app	O
engine	O
ideas	O
,	O
you	O
could	O
use	O
memcache	O
as	O
a	O
temporary	O
store	O
for	O
your	O
counter	O
.	O

Incrementing	O
a	O
memcache	O
counter	O
is	O
faster	O
than	O
using	O
the	O
MySql	B-API
heap	O
tables	O
(	O
I	O
think	O
)	O
.	O

Once	O
every	O
five	O
or	O
ten	O
seconds	O
,	O
you	O
could	O
read	O
the	O
memcache	O
counter	O
and	O
write	O
that	O
number	O
into	O
your	O
DB	O
.	O

You	O
could	O
take	O
your	O
webserver	O
'	O
s	O
Access	O
log	O
(	O
Apache	B-Orgs
:	O
access.log	B-API
)	O
and	O
evaluate	O
it	O
time	O
and	O
again	O
(	O
cronjob	O
)	O
in	O
case	O
you	O
do	O
not	O
need	O
to	O
have	O
the	O
data	O
at	O
hand	O
at	O
the	O
exact	O
moment	O
in	O
time	O
when	O
someone	O
visits	O
your	O
site	O
.	O

Usually	O
,	O
the	O
access.log	B-API
is	O
generated	O
anyway	O
and	O
contains	O
the	O
requested	O
resource	O
as	O
well	O
as	O
time	O
,	O
date	O
and	O
the	O
user	O
'	O
s	O
IP	O
.	O

This	O
way	O
you	O
do	O
not	O
have	O
to	O
route	O
all	O
trafic	O
through	O
a	O
php-script	O
.	O

Lean	O
,	O
mean	O
counting	O
machine	O
.	O

You	O
can	O
use	O
Redis	O
-	O
its	O
very	O
fast	O
key-value	O
storage	O
with	O
support	O
for	O
atomic	O
increments	O
.	O

If	O
need	O
will	O
arise	O
--	O
counts	O
data	O
could	O
be	O
splitted	O
between	O
multiple	O
servers	O
easily	O
.	O

I've	O
done	O
something	O
very	O
similar	O
,	O
on	O
a	O
similar	O
scale	O
(	O
multiple	O
servers	O
,	O
hundreds	O
of	O
domains	O
,	O
several	O
thousand	O
hits	O
per	O
hour	O
)	O
and	O
log	O
file	O
analysis	O
was	O
definitely	O
the	O
way	O
to	O
go	O
.	O

(	O
It	O
also	O
checked	O
hit	O
rates	O
,	O
weighted	O
them	O
by	O
file	O
type	O
,	O
and	O
blacklisted	O
IP	O
addresses	O
at	O
the	O
firewall	O
if	O
they	O
were	O
making	O
too	O
many	O
requests	O
;	O
its	O
intended	O
purpose	O
was	O
to	O
auto-block	O
bad	O
bots	O
,	O
not	O
to	O
just	O
be	O
a	O
counter	O
,	O
but	O
counting	O
was	O
an	O
essential	O
piece	O
of	O
it	O
.	O
)	O

No	O
performance	O
impact	O
on	O
the	O
web	O
server	O
process	O
itself	O
,	O
since	O
it	O
'	O
s	O
not	O
doing	O
any	O
additional	O
work	O
there	O
,	O
and	O
you	O
could	O
easily	O
publish	O
periodically-updated	O
hit	O
counts	O
by	O
injecting	O
them	O
into	O
the	O
site	O
'	O
s	O
database	O
every	O
minute	O
/	O
5	O
minutes	O
/	O
100	O
hits	O
/	O
whatever	O
without	O
having	O
to	O
lock	O
the	O
relevant	O
row	O
/	O
table	O
/	O
database	O
(	O
depending	O
on	O
the	O
locking	O
mechanism	O
in	O
use	O
)	O
on	O
every	O
hit	O
.	O

Without	O
a	O
doubt	O
,	O
Redis	O
is	O
perfect	O
for	O
this	O
problem	O
.	O

It	O
requires	O
about	O
a	O
minute	O
to	O
setup	O
and	O
install	O
,	O
supports	O
atomic	O
increments	O
,	O
is	O
incredibly	O
fast	O
,	O
has	O
client	O
libs	O
for	O
python	B-PL
and	O
php	B-PL
(	O
and	O
many	O
other	O
languages	O
)	O
,	O
is	O
durable	O
(	O
snapshots	O
,	O
journal	O
,	O
replication	O
)	O
.	O

Store	O
each	O
counter	O
to	O
its	O
own	O
key	O
.	O

Then	O
simply	O
@codeSnippetRemoved	O
